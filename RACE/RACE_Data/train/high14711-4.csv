,answers,options,questions,article,id
4,A,"['Determine what is moral and ethical.', 'Design some large-scale experiments.', 'Set rules for man-machine interaction.', 'Develop a more sophisticated program.']",What is most difficult to do when we turn human values into a programmable code?,"As Artificial Intelligence(AI) becomes increasingly sophisticated, there are growing concerns that robots could become a threat. This danger can be avoided, according to computer science professor Stuart Russell, if we figure out how to turn human values into a programmable code.
Russell argues that as robots take on more complicated tasks, it's necessary to translate our morals into AI language.
For example, if a robot does chores around the house, you wouldn't want it to put the pet cat in the oven to make dinner for the hungry children. ""You would want that robot preloaded with a good set of values,"" said Russell.
Some robots are already programmed with basic human values. For example, mobile robots have been programmed to keep a comfortable distance from humans. Obviously there are cultural differences, but if you were talking to another person and they came up close in your personal space, you wouldn't think that's the kind of thing a properly brought-up person would do.
It will be possible to create more sophisticated moral machines, if only we can find a way to set out human values as clear rules.
Robots could also learn values from drawing patterns from large sets of data on human behavior. They are dangerous only if programmers are careless.
The biggest concern with robots going against human values is that human beings fail to so sufficient testing and they've produced a system that will break some kind of taboo .
One simple check would be to program a robot to check the correct course of action with a human when presented with an unusual situation.
If the robot is unsure whether an animal is suitable for the microwave, it has the opportunity to stop, send out beeps , and ask for directions from a human. If we humans aren't quite sure about a decision, we go and ask somebody else.
The most difficult step in programming values will be deciding exactly what we believe in moral, and how to create a set of ethical rules. But if we come up with an answer, robots could be good for humanity.",high14711.txt
